{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# Configuration: how many of each type of node to create\n",
    "num_authors = 50         \n",
    "num_papers = 150         \n",
    "num_keywords = 40        \n",
    "num_conferences = 15    \n",
    "num_venues = 15         \n",
    "num_journals = 10       \n",
    "num_volumes = 20    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"This paper explores the impact of machine learning algorithms on data analysis efficiency.\",\n",
    "    \"We present a novel approach for optimizing graph database queries.\",\n",
    "    \"This study analyzes the effects of large-scale distributed systems in cloud computing.\",\n",
    "    \"In this work, we investigate the security challenges in IoT networks.\",\n",
    "    \"This paper proposes a new model for natural language processing tasks.\",\n",
    "    \"The research examines the evolution of data privacy regulations worldwide.\",\n",
    "    \"An empirical study on the performance of blockchain technologies.\",\n",
    "    \"We provide a comparative analysis of various AI optimization techniques.\",\n",
    "    \"This study evaluates the scalability of real-time recommendation systems.\",\n",
    "    \"A new framework for cybersecurity threat detection is introduced.\"\n",
    "]\n",
    "\n",
    "# Components to generate unique titles\n",
    "adjectives = [\"Efficient\", \"Scalable\", \"Robust\", \"Secure\", \"Advanced\", \"Distributed\", \"Optimized\", \"Flexible\"]\n",
    "nouns = [\"Framework\", \"Model\", \"Approach\", \"Architecture\", \"Method\", \"Algorithm\", \"Technique\", \"System\"]\n",
    "fields = [\n",
    "    \"Machine Learning\",\n",
    "    \"Blockchain\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Natural Language Processing\",\n",
    "    \"Quantum Computing\",\n",
    "    \"Data Privacy\",\n",
    "    \"Graph Databases\",\n",
    "    \"Cloud Computing\",\n",
    "    \"Healthcare AI\",\n",
    "    \"IoT Networks\",\n",
    "]\n",
    "\n",
    "# Helper function to generate a unique title\n",
    "def generate_unique_title(existing_titles):\n",
    "    while True:\n",
    "        title = f\"{random.choice(adjectives)} {random.choice(nouns)} for {random.choice(fields)}\"\n",
    "        if title not in existing_titles:\n",
    "            existing_titles.add(title)\n",
    "            return title\n",
    "\n",
    "num_papers = 150\n",
    "\n",
    "existing_titles = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authors\n",
    "with open('authors.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'name'])  # header\n",
    "    for i in range(1, num_authors + 1):\n",
    "        writer.writerow([i, fake.name()])\n",
    "\n",
    "# Create keywords\n",
    "with open('keywords.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'name'])  # header\n",
    "    for i in range(1, num_keywords + 1):\n",
    "        writer.writerow([i, fake.word()])\n",
    "\n",
    "# Create papers\n",
    "with open('papers.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'title', 'abstract', 'doi'])  # header\n",
    "    for i in range(1, num_papers + 1):\n",
    "        title = generate_unique_title(existing_titles)\n",
    "        abstract = random.choice(topics)\n",
    "        doi = fake.uuid4()\n",
    "        writer.writerow([i, title, abstract, doi])\n",
    "\n",
    "# Create proceeding editions\n",
    "with open('proceedings.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'number', 'start_date', 'end_date'])  # header\n",
    "    for i in range(1, num_conferences + 1):\n",
    "        start = fake.date_between(start_date='-5y', end_date='today')\n",
    "        end = start + timedelta(days=3)  # conference lasts 3 days\n",
    "        writer.writerow([i, i, start, end])\n",
    "\n",
    "# Create venues\n",
    "with open('venues.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'venue_name'])  # header\n",
    "    for i in range(1, num_venues + 1):\n",
    "        writer.writerow([i, fake.city()])\n",
    "\n",
    "# Create journals\n",
    "with open('journals.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'journal_name'])  # header\n",
    "    for i in range(1, num_journals + 1):\n",
    "        writer.writerow([i, fake.company()])\n",
    "\n",
    "# Create journal volumes\n",
    "with open('journal_volumes.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'volume', 'year', 'issue'])  # header\n",
    "    for i in range(1, num_volumes + 1):\n",
    "        writer.writerow([i, random.randint(1, 100), random.randint(2018, 2024), random.randint(1, 4)])\n",
    "\n",
    "# Create citation relationships between papers\n",
    "with open('citations.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['source_paper', 'target_paper'])  # header\n",
    "    for _ in range(300):  # <-- change from 10 to 300\n",
    "        src = random.randint(1, num_papers)\n",
    "        tgt = random.randint(1, num_papers)\n",
    "        if src != tgt:  # avoid self-citation\n",
    "            writer.writerow([src, tgt])\n",
    "\n",
    "# Create WROTE relationships (author wrote paper)\n",
    "with open('wrote.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['author_id', 'paper_id', 'corresponding'])\n",
    "    for _ in range(200):\n",
    "        writer.writerow([\n",
    "            random.randint(1, num_authors),\n",
    "            random.randint(1, num_papers),\n",
    "            random.choice([True, False])\n",
    "        ])\n",
    "\n",
    "# Create HAS_KEYWORD relationships (paper has keyword)\n",
    "with open('has_keyword.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['paper_id', 'keyword_id'])\n",
    "    for _ in range(300):\n",
    "        writer.writerow([\n",
    "            random.randint(1, num_papers),\n",
    "            random.randint(1, num_keywords)\n",
    "        ])\n",
    "\n",
    "# Create PUBLISHED_IN relationships (paper published in proceeding or journal_volume)\n",
    "with open('published_in.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['paper_id', 'proceeding_id', 'journal_volume_id', 'date_accepted', 'pages'])\n",
    "    for _ in range(150):\n",
    "        paper_id = random.randint(1, num_papers)\n",
    "        if random.random() < 0.5:\n",
    "            proceeding_id = random.randint(1, num_conferences)\n",
    "            journal_volume_id = ''\n",
    "        else:\n",
    "            proceeding_id = ''\n",
    "            journal_volume_id = random.randint(1, num_volumes)\n",
    "        date_accepted = fake.date_between(start_date='-3y', end_date='today')\n",
    "        pages = f\"{random.randint(1, 10)}-{random.randint(11, 20)}\"\n",
    "        writer.writerow([paper_id, proceeding_id, journal_volume_id, date_accepted, pages])\n",
    "\n",
    "# Create HELD_IN relationships (proceeding edition held in venue)\n",
    "with open('held_in.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['proceeding_id', 'venue_id'])\n",
    "    for i in range(1, num_conferences + 1):\n",
    "        writer.writerow([\n",
    "            i,\n",
    "            random.randint(1, num_venues)\n",
    "        ])\n",
    "\n",
    "# Create _RELATED relationships (proceeding edition related to something)\n",
    "with open('related.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['proceeding_id', 'type', 'name'])\n",
    "    for i in range(1, num_conferences + 1):\n",
    "        writer.writerow([\n",
    "            i,\n",
    "            random.choice(['Workshop', 'Symposium', 'Seminar']),\n",
    "            fake.bs().title()\n",
    "        ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
